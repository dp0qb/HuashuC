{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213dba68-99b6-4e7e-aa2d-6c71124f7d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd2d2d12-0693-4904-945a-3c5d8c5501c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(city_name):\n",
    "    query = str(city_name.encode('utf-8'))[1:].replace(\"'\", \"\").replace(\"\\\\x\", \"%25\").upper()\n",
    "    return query\n",
    "\n",
    "def get_sight_url(response):\n",
    "    html_doc = response.text\n",
    "    soup = BeautifulSoup(html_doc, 'lxml')\n",
    "    tags = soup.find_all(attrs={\"data-beacon\": \"SC_resault\"})\n",
    "    sight_url = \"\"\n",
    "    get_url = False\n",
    "    if len(tags) != 0:\n",
    "        sight_url = tags[0][\"href\"] + \"-jingdian\"\n",
    "        get_url = True\n",
    "    return (sight_url, get_url)\n",
    "\n",
    "def get_proxy():\n",
    "    return requests.get(\"http://127.0.0.1:5010/get/\").json()\n",
    "\n",
    "def delete_proxy(proxy):\n",
    "    requests.get(\"http://127.0.0.1:5010/delete/?proxy={}\".format(proxy))\n",
    "\n",
    "def getResponse(base_url, headers):\n",
    "    # ....\n",
    "    retry_count = 5\n",
    "    proxy = get_proxy().get(\"proxy\")\n",
    "    while retry_count > 0:\n",
    "        try:\n",
    "            html = requests.get(base_url, headers=headers, proxies={\"http\": \"http://{}\".format(proxy)})\n",
    "            # 使用代理访问\n",
    "            return html\n",
    "        except Exception:\n",
    "            retry_count -= 1\n",
    "    # 删除代理池中代理\n",
    "    delete_proxy(proxy)\n",
    "    return None\n",
    "    \n",
    "data_folder = r\"./original_data\"\n",
    "data_file_names = os.listdir(data_folder)\n",
    "city_names = map(lambda x: x.split('.')[0], data_file_names)\n",
    "base_url = r\"https://travel.qunar.com/search/all/\"\n",
    "params = {}\n",
    "headers = {}\n",
    "with open(\"./output/sight_url.txt\", 'a', encoding=\"utf-8\") as f:\n",
    "    for city_name in city_names:\n",
    "        print(city_name)\n",
    "        ua = UserAgent()\n",
    "        headers[\"User-Agent\"] = ua.random\n",
    "        url = base_url + get_query(city_name)\n",
    "        response = getResponse(url, headers)\n",
    "        print(response.status_code)\n",
    "        (sight_url, get_url) = get_sight_url(response)\n",
    "        f.write(city_name)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(sight_url)\n",
    "        f.write(\"\\n\")\n",
    "        print(sight_url)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4822bfa-8940-4e86-a3f7-b9bf920c794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ip\":\"110.82.6.157\",\"state\":\"ok\"}\n"
     ]
    }
   ],
   "source": [
    "# 提取代理API接口，获取1个代理IP\n",
    "api_url = \"http://v2.api.juliangip.com/dynamic/getips?auto_white=1&num=1&pt=1&result_type=text&split=1&trade_no=1129780214579896&sign=5e8e521b200e03ade682e8906972d00e\"\n",
    "\n",
    "# 获取API接口返回的代理IP\n",
    "proxy_ip = requests.get(api_url).text\n",
    "\n",
    "# 用户名密码认证(动态代理/独享代理)\n",
    "username = \"13437953591\"\n",
    "password = \"4XrQ6jfh\"\n",
    "proxies = {\n",
    "\"http\": \"http://%(user)s:%(pwd)s@%(proxy)s/\" % {\"user\": username, \"pwd\": password, \"proxy\": proxy_ip},\n",
    "\"https\": \"http://%(user)s:%(pwd)s@%(proxy)s/\" % {\"user\": username, \"pwd\": password, \"proxy\": proxy_ip},\n",
    "}\n",
    "\n",
    "# 白名单方式（需提前设置白名单）\n",
    "# proxies = {\n",
    "#     \"http\": \"http://%(proxy)s/\" % {\"proxy\": proxy_ip},\n",
    "#     \"https\": \"http://%(proxy)s/\" % {\"proxy\": proxy_ip},\n",
    "# }\n",
    "\n",
    "# 要访问的目标网页\n",
    "target_url = \"https://www.juliangip.com/api/general/Test\"\n",
    "\n",
    "# 使用代理IP发送请求\n",
    "response = requests.get(target_url, proxies=proxies)\n",
    "\n",
    "# 获取页面内容\n",
    "if response.status_code == 200:\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff0435-fff5-4523-937f-752d0f35df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"<div class=\"b_paging\"><em class=\"page cur\">1</em><a class=\"page\" href=\"https://travel.qunar.com/p-cs298037-alashanmeng-jingdian-1-2\">2</a><a class=\"page\" href=\"https://travel.qunar.com/p-cs298037-alashanmeng-jingdian-1-3\">3</a><a class=\"page\" href=\"https://travel.qunar.com/p-cs298037-alashanmeng-jingdian-1-4\">4</a><a class=\"page\" href=\"https://travel.qunar.com/p-cs298037-alashanmeng-jingdian-1-5\">5</a><a class=\"page\" href=\"https://travel.qunar.com/p-cs298037-alashanmeng-jingdian-1-6\">6</a><em class=\"dot\">...</em><a class=\"page\" href=\"https://travel.qunar.com/p-cs298037-alashanmeng-jingdian-1-199\">199</a><a class=\"page\" href=\"https://travel.qunar.com/p-cs298037-alashanmeng-jingdian-1-200\">200</a><a class=\"page next\" href=\"https://travel.qunar.com/p-cs298037-alashanmeng-jingdian-1-2\">下一页</a></div>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0c50cc-8da9-47d3-b8b5-a7070ca67abf",
   "metadata": {},
   "source": [
    "# 高铁数据爬取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0e624-03f0-4436-98ab-b50645e691a6",
   "metadata": {},
   "source": [
    "## 获取所有高铁页面链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "37e50167-551f-469c-92c3-56b09730663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://train.hao86.com/%E9%AB%98%E9%80%9F/\"\n",
    "headers = {}\n",
    "ua = UserAgent()\n",
    "headers[\"User-Agent\"] = ua.random\n",
    "response = requests.get(url, headers=headers)\n",
    "html_doc = response.text\n",
    "soup = BeautifulSoup(html_doc, 'lxml')\n",
    "uls = soup.find_all(\"ul\", attrs={\"id\": \"scrollbar\"})\n",
    "lis = uls[0].find_all('li')\n",
    "hsr_data = {\n",
    "    \"hsrs\": []\n",
    "}\n",
    "for li in lis:\n",
    "    hsr = {}\n",
    "    hsr_name = li.contents[0][\"href\"].replace(\"/\", \"\")\n",
    "    hsr[\"name\"]= hsr_name\n",
    "    hsr[\"url\"] = \"https://train.hao86.com\" + li.contents[0][\"href\"]\n",
    "    hsr_data[\"hsrs\"].append(hsr)\n",
    "with open(\"./output/hsr_data.json\",'w+') as f:\n",
    "    json.dump(hsr_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3009b7-c66f-4b85-8836-9fc2e8051197",
   "metadata": {},
   "source": [
    "## 爬取每个页面的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "9de7f62d-f037-4872-af9d-18797f16d92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未找到G185的途经车站。\n",
      "未找到G1813的途经车站。\n",
      "未找到G1822的途经车站。\n",
      "未找到G1826的途经车站。\n",
      "未找到G1828的途经车站。\n",
      "未找到G1832的途经车站。\n",
      "未找到G1852的途经车站。\n",
      "未找到G1862的途经车站。\n",
      "未找到G1866的途经车站。\n",
      "未找到G1869的途经车站。\n",
      "未找到G1870的途经车站。\n",
      "未找到G1874的途经车站。\n",
      "未找到G1880的途经车站。\n",
      "未找到G1887的途经车站。\n",
      "未找到G1896的途经车站。\n",
      "未找到G1865的途经车站。\n",
      "未找到G701的途经车站。\n",
      "未找到G702的途经车站。\n",
      "未找到G703的途经车站。\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[417], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m (get_succ, stations_table) \u001b[38;5;241m=\u001b[39m get_stations_table(response)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_succ:\n\u001b[1;32m---> 43\u001b[0m     stations \u001b[38;5;241m=\u001b[39m get_stations(stations_table)\n\u001b[0;32m     44\u001b[0m     hsr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstations\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stations\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[417], line 23\u001b[0m, in \u001b[0;36mget_stations\u001b[1;34m(stations_table)\u001b[0m\n\u001b[0;32m     21\u001b[0m stations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tr \u001b[38;5;129;01min\u001b[39;00m trs:\n\u001b[1;32m---> 23\u001b[0m     station \u001b[38;5;241m=\u001b[39m tr\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mstring\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     24\u001b[0m     stations\u001b[38;5;241m.\u001b[39mappend(station)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stations\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'string'"
     ]
    }
   ],
   "source": [
    "def get_stations_table(response):\n",
    "    html_doc = response.text\n",
    "    soup = BeautifulSoup(html_doc, 'lxml')\n",
    "    divs = soup.find_all(\"div\", attrs={\"class\": \"main_conter_Article clearfix\"})\n",
    "    get_succ = False\n",
    "    stations_table = None\n",
    "    pattern = re.compile(r\"途经车站\")\n",
    "    if len(divs) != 0:\n",
    "        for div in divs:\n",
    "            for i in range(len(div.contents)):\n",
    "                child = div.contents[i]\n",
    "                if child !=\"\\n\" and len(child.find_all(string=pattern)) > 0:\n",
    "                    get_succ = True\n",
    "                    stations_table = div.find_all(\"div\", attrs={\"class\": \"station\"})[0].contents\n",
    "                    stations_table = list(filter(lambda x: x!=\"\\n\", stations_table))[0]\n",
    "                    break\n",
    "    return (get_succ, stations_table)\n",
    "\n",
    "def get_stations(stations_table):\n",
    "    trs = stations_table.find_all(\"tr\")[1:]\n",
    "    stations = []\n",
    "    for tr in trs:\n",
    "        station = tr.find_all(\"td\")[1].a.string.strip()\n",
    "        stations.append(station)\n",
    "    return stations\n",
    "\n",
    "with open(\"./output/hsr_data.json\",'r+') as f:\n",
    "    hsr_data = json.load(f)\n",
    "hsrs = hsr_data[\"hsrs\"]\n",
    "failed_count = 0\n",
    "headers = {}\n",
    "for hsr in hsrs:\n",
    "    url = hsr[\"url\"]\n",
    "    ua = UserAgent()\n",
    "    headers[\"User-Agent\"] = ua.random\n",
    "    response = getResponse(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(\"请求失败！\")\n",
    "    else:\n",
    "        response.encoding = \"utf-8\"\n",
    "        (get_succ, stations_table) = get_stations_table(response)\n",
    "        if get_succ:\n",
    "            stations = get_stations(stations_table)\n",
    "            hsr[\"stations\"] = stations\n",
    "        else:\n",
    "            failed_count += 1\n",
    "            print(f\"未找到{hsr[\"name\"]}的途经车站。\")\n",
    "    time.sleep(1)\n",
    "\n",
    "with open(\"./output/hsr_data.json\",'w+') as f:\n",
    "    json.dump(hsr_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d6bda5",
   "metadata": {},
   "source": [
    "## 爬取两个城市之间的最快高铁速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5668a33b-46f9-4188-a6e4-60a296c1313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "万宁 三亚\n",
      "未找到表格！\n",
      "三亚 万宁\n",
      "未找到表格！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "万宁 东方\n",
      "未找到表格！\n",
      "东方 万宁\n",
      "未找到表格！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "三明 上海\n",
      "未找到表格！\n",
      "上海 三明\n",
      "未找到表格！\n",
      "G2380\n",
      "01:30\n",
      "G322\n",
      "01:39\n",
      "G322\n",
      "01:23\n",
      "G1654\n",
      "01:49\n",
      "G1654\n",
      "01:33\n",
      "G3142\n",
      "01:53\n",
      "G3142\n",
      "01:37\n",
      "G1651\n",
      "01:19\n",
      "G1509\n",
      "01:33\n",
      "G3141\n",
      "01:36\n",
      "G3141\n",
      "01:53\n",
      "G2379\n",
      "01:26\n",
      "G323\n",
      "01:23\n",
      "G323\n",
      "01:39\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "三门峡 上海\n",
      "未找到表格！\n",
      "上海 三门峡\n",
      "未找到表格！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "三门峡 东莞\n",
      "未找到表格！\n",
      "东莞 三门峡\n",
      "未找到表格！\n",
      "G4917\n",
      "02:35\n",
      "G1383\n",
      "02:47\n",
      "G1651\n",
      "02:57\n",
      "G2365\n",
      "02:49\n",
      "G1371\n",
      "02:51\n",
      "G2189\n",
      "02:55\n",
      "G1631\n",
      "03:00\n",
      "G1505\n",
      "03:12\n",
      "G1337\n",
      "03:00\n",
      "G1509\n",
      "03:23\n",
      "G1655\n",
      "02:42\n",
      "G1377\n",
      "02:51\n",
      "G1501\n",
      "02:42\n",
      "G1657\n",
      "02:37\n",
      "G1375\n",
      "02:57\n",
      "G1333\n",
      "02:43\n",
      "G1387\n",
      "02:43\n",
      "G1471\n",
      "02:46\n",
      "G1369\n",
      "02:49\n",
      "G1389\n",
      "02:35\n",
      "G1353\n",
      "02:46\n",
      "G1329\n",
      "02:41\n",
      "G2141\n",
      "02:40\n",
      "G99\n",
      "02:24\n",
      "G1635\n",
      "02:43\n",
      "G1637\n",
      "03:14\n",
      "G1305\n",
      "02:21\n",
      "G1359\n",
      "02:40\n",
      "G1583\n",
      "02:57\n",
      "G1361\n",
      "02:51\n",
      "G1385\n",
      "02:52\n",
      "G1363\n",
      "02:47\n",
      "G1639\n",
      "02:49\n",
      "G1365\n",
      "02:40\n",
      "G1395\n",
      "02:45\n",
      "G1689\n",
      "02:51\n",
      "G1690\n",
      "02:53\n",
      "G1382\n",
      "02:35\n",
      "G1384\n",
      "02:47\n",
      "G1632\n",
      "02:46\n",
      "G1386\n",
      "03:02\n",
      "G1634\n",
      "02:57\n",
      "G1350\n",
      "02:48\n",
      "G1352\n",
      "02:48\n",
      "G1636\n",
      "02:50\n",
      "G1638\n",
      "02:46\n",
      "G1390\n",
      "02:39\n",
      "G1322\n",
      "02:51\n",
      "G1362\n",
      "02:51\n",
      "G1378\n",
      "02:40\n",
      "G1388\n",
      "02:46\n",
      "G100\n",
      "02:25\n",
      "G1654\n",
      "03:05\n",
      "G1656\n",
      "02:51\n",
      "G1502\n",
      "03:05\n",
      "G1328\n",
      "03:13\n",
      "G1302\n",
      "02:47\n",
      "G1374\n",
      "02:54\n",
      "G1394\n",
      "02:39\n",
      "G1376\n",
      "03:09\n",
      "G1506\n",
      "02:49\n",
      "G1658\n",
      "02:53\n",
      "G2366\n",
      "02:47\n",
      "G1472\n",
      "02:48\n",
      "G1660\n",
      "02:54\n",
      "G4918\n",
      "02:22\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "上海 东莞\n",
      "未找到表格！\n",
      "东莞 上海\n",
      "未找到表格！\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n",
      "G99\n",
      "04:37\n",
      "无直达线路或请求失败！\n",
      "无直达线路或请求失败！\n"
     ]
    }
   ],
   "source": [
    "def time_select(response, start_city, end_city):\n",
    "    response.encoding = \"utf-8\"\n",
    "    html_doc = response.text\n",
    "    soup = BeautifulSoup(html_doc, 'lxml')\n",
    "    pattern = re.compile(r\"^G\")\n",
    "    shortest_time = -1\n",
    "    tables = soup.find_all(\"table\")\n",
    "    if len(tables) == 1:\n",
    "        table = tables[0]\n",
    "        trs = table.find_all(\"tr\")\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all(\"td\")\n",
    "            if len(tds) > 0:\n",
    "                hsr_name = tds[0].a.find_all(string=pattern)\n",
    "                if len(hsr_name) > 0:\n",
    "                    print(hsr_name[0])\n",
    "                    time = tr.find_all(\"td\")[-1].string\n",
    "                    print(time)\n",
    "    elif len(tables) < 1:\n",
    "        print(start_city, end_city)\n",
    "        print(\"未找到表格！\")\n",
    "    else:\n",
    "        print(\"表格数量超过1！\")\n",
    "    return shortest_time\n",
    "\n",
    "\n",
    "def get_shortest_time(start_city, end_city, headers):\n",
    "    base_url = \"https://train.hao86.com/\"\n",
    "    query = str((start_city + \"-\" + end_city).encode(\"utf-8\"))[1:].replace(\"'\", \"\").replace(\"\\\\x\", \"%\").upper() + \"/\"\n",
    "    url = base_url + query\n",
    "    response = getResponse(url, headers=headers)\n",
    "    get_succ = False\n",
    "    shortest_time = -1\n",
    "    if response.status_code != 200:\n",
    "        print(\"无直达线路或请求失败！\")\n",
    "    else:\n",
    "        get_succ = True\n",
    "        shortest_time = time_select(response, start_city, end_city)\n",
    "    #解析\n",
    "    return (get_succ, shortest_time)\n",
    "    \n",
    "\n",
    "def save_time(start_city, end_city, get_succ, shortest_time, routes_data):\n",
    "    if get_succ:\n",
    "        route_name = f\"{start_city}-{end_city}\"\n",
    "        routes_time = {\n",
    "            route_name: shortest_time\n",
    "        }\n",
    "        routes_data[\"routes_time\"].append(routes_time)\n",
    "\n",
    "\n",
    "data_folder = r\"./original_data\"\n",
    "data_file_names = os.listdir(data_folder)\n",
    "city_names = list(map(lambda x: x.split('.')[0], data_file_names))\n",
    "city_names = city_names[0:10]\n",
    "count = 0\n",
    "headers = {}\n",
    "routes_data = {\n",
    "    \"routes_time\": []\n",
    "}\n",
    "for i in range(len(city_names)):\n",
    "    for j in range(i+1, len(city_names)):\n",
    "        start_city = city_names[i]\n",
    "        end_city = city_names[j]\n",
    "        ua = UserAgent()\n",
    "        headers[\"User-Agent\"] = ua.random\n",
    "        (get_succ, shortest_time) = get_shortest_time(start_city, end_city, headers)\n",
    "        save_time(start_city, end_city, get_succ, shortest_time, routes_data)\n",
    "        (get_succ, shortest_time) = get_shortest_time(end_city, start_city, headers)\n",
    "        save_time(end_city, start_city, get_succ, shortest_time, routes_data)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5121f29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'routes_time': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
